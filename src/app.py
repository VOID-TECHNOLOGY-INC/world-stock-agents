from __future__ import annotations

import json
from datetime import date, datetime
from pathlib import Path
from typing import List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

import typer
import pandas as pd
from rich import print
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
from rich.panel import Panel
from rich.table import Table
from rich.live import Live
from rich.layout import Layout

from .config import load_config
from .io.writers import ensure_output_dir, write_json, write_text
from .io.loaders import load_universe
from .agents.regions import RegionAgent
from .agents.chair import build_report
from .agents.optimizer import optimize_portfolio
from .tools.marketdata import MarketDataClient
from .tools.fundamentals import FundamentalsClient
from .tools.news import NewsClient
from .agents.risk import RiskAgent
from .agents.macro import MacroAgent
from .tools.risk_tool import compute_returns
from .tools.buy_signal import evaluate_buy_signals


app = typer.Typer(add_completion=False, no_args_is_help=True)
console = Console()


def _parse_date(d: str) -> date:
    return datetime.strptime(d, "%Y-%m-%d").date()


def _create_progress_layout():
    """é€²æ—è¡¨ç¤ºç”¨ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½œæˆ"""
    layout = Layout()
    layout.split_column(
        Layout(name="header", size=3),
        Layout(name="main"),
        Layout(name="footer", size=3)
    )
    layout["main"].split_row(
        Layout(name="progress", ratio=2),
        Layout(name="status", ratio=1)
    )
    return layout


def _create_status_table():
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    table = Table(title="ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
    table.add_column("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", style="cyan")
    table.add_column("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", style="green")
    table.add_column("å‡¦ç†æ™‚é–“", style="yellow")
    return table


def _process_region_parallel(region: str, as_of: date, top_n: int, output_dir: Path, progress, task_id: int, workers: int = 4) -> tuple[str, dict, Any]:
    """åœ°åŸŸåˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹é–¢æ•°ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰å®‰å…¨ãªé€²æ—æ›´æ–°ï¼‰"""
    def _safe_update(**kwargs) -> None:
        try:
            # rich.Progress ã¯ call_from_thread ã‚’æä¾›
            progress.call_from_thread(progress.update, task_id, **kwargs)
        except Exception:
            progress.update(task_id, **kwargs)
    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å…±æœ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥/æ¥ç¶šã®å†åˆ©ç”¨ï¼‰
        _safe_update(advance=20, description=f"[cyan]åœ°åŸŸ {region} ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")
        mkt = MarketDataClient(max_workers=workers)
        fcli = FundamentalsClient(max_workers=workers)
        ncli = NewsClient(max_workers=min(workers, 3))  # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯æ§ãˆã‚ã«
        agent = RegionAgent(name=region, universe="REAL", tools={
            "marketdata": mkt,
            "fundamentals": fcli,
            "news": ncli,
        })
        
        # å€™è£œé¸å®š
        _safe_update(advance=30, description=f"[cyan]åœ°åŸŸ {region} å€™è£œé¸å®šä¸­...")
        out = agent.run(as_of=as_of, top_n=top_n)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        _safe_update(advance=20, description=f"[cyan]åœ°åŸŸ {region} ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
        out_path = output_dir / f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json"
        write_json(out_path, out)
        
        # æˆé•·å€™è£œã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        growth_out_path = output_dir / f"growth_{region}_{as_of.strftime('%Y%m%d')}.json"
        write_json(
            growth_out_path,
            {
                "region": region,
                "as_of": as_of.strftime("%Y-%m-%d"),
                "universe": out.get("universe", "REAL"),
                "candidates": out.get("growth_candidates", []),
            },
        )
        
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆåŒä¸€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å†åˆ©ç”¨ï¼‰
        _safe_update(advance=20, description=f"[cyan]åœ°åŸŸ {region} ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        uni_tickers = [c["ticker"] for c in out.get("candidates", [])]
        region_prices = {}
        if uni_tickers:
            prices, _ = mkt.get_prices(uni_tickers, lookback_days=260)
            region_prices = prices
        
        _safe_update(advance=10, description=f"[green]åœ°åŸŸ {region} å®Œäº†")
        
        return region, out, region_prices
        
    except Exception as e:
        try:
            progress.call_from_thread(progress.update, task_id, description=f"[red]åœ°åŸŸ {region} ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception:
            progress.update(task_id, description=f"[red]åœ°åŸŸ {region} ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise e


@app.command()
def candidates(
    regions: str = typer.Option("JP,US", help="å¯¾è±¡åœ°åŸŸ (CSV)"),
    run_date: str = typer.Option(datetime.today().strftime("%Y-%m-%d"), "--date"),
    output: str = typer.Option("./artifacts", help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"),
    top_n: int = typer.Option(50, help="å„åœ°åŸŸã®ä¸Šä½å€™è£œæ•°"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãªé€²æ—è¡¨ç¤º"),
    parallel: bool = typer.Option(True, "--parallel/--sequential", help="ä¸¦åˆ—å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã¾ãŸã¯é€æ¬¡å®Ÿè¡Œ"),
    workers: int = typer.Option(4, "--workers", "-w", help="ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4ï¼‰"),
):
    """åœ°åŸŸåˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã€å€™è£œJSONã‚’å‡ºåŠ›ã™ã‚‹ã€‚"""
    as_of = _parse_date(run_date)
    cfg = load_config(output)
    ensure_output_dir(cfg.output_dir)

    region_list = [r.strip().upper() for r in regions.split(",") if r.strip()]
    
    if verbose:
        console.print(Panel(
            f"[bold blue]åœ°åŸŸåˆ¥å€™è£œé¸å®šé–‹å§‹[/bold blue]\n"
            f"åœ°åŸŸ: {', '.join(region_list)}  æ—¥ä»˜: {as_of}\n"
            f"å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {'ä¸¦åˆ—' if parallel else 'é€æ¬¡'}",
            title="å®Ÿè¡Œæƒ…å ±"
        ))
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            results: List[dict] = []
            
            if parallel and len(region_list) > 1:
                # ä¸¦åˆ—å®Ÿè¡Œ
                tasks = {}
                with ThreadPoolExecutor(max_workers=min(len(region_list), workers)) as executor:
                    # ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
                    for region in region_list:
                        task_id = progress.add_task(f"[cyan]åœ°åŸŸ {region} å‡¦ç†ä¸­...", total=100)
                        future = executor.submit(_process_region_parallel, region, as_of, top_n, Path(cfg.output_dir), progress, task_id)
                        tasks[future] = (region, task_id)
                    
                    # å®Œäº†ã‚’å¾…æ©Ÿ
                    for future in as_completed(tasks):
                        region, task_id = tasks[future]
                        try:
                            region_name, out, region_prices = future.result()
                            results.append(out)
                            console.print(f"âœ… [green]candidates saved:[/green] candidates_{region}_{as_of.strftime('%Y%m%d')}.json")
                            console.print(f"âœ… [green]growth saved:[/green] growth_{region}_{as_of.strftime('%Y%m%d')}.json")
                        except Exception as e:
                            console.print(f"âŒ [red]åœ°åŸŸ {region} ã§ã‚¨ãƒ©ãƒ¼:[/red] {str(e)}")
            else:
                # é€æ¬¡å®Ÿè¡Œï¼ˆæ—¢å­˜ã®å®Ÿè£…ï¼‰
                for i, region in enumerate(region_list):
                    task = progress.add_task(f"[cyan]åœ°åŸŸ {region} å‡¦ç†ä¸­...", total=100)
                    
                    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
                    progress.update(task, advance=20, description=f"[cyan]åœ°åŸŸ {region} ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")
                    agent = RegionAgent(name=region, universe="REAL", tools={
                        "marketdata": MarketDataClient(max_workers=workers),
                        "fundamentals": FundamentalsClient(max_workers=workers),
                        "news": NewsClient(max_workers=min(workers, 3))
                    })
                    
                    progress.update(task, advance=30, description=f"[cyan]åœ°åŸŸ {region} å€™è£œé¸å®šä¸­...")
                    out = agent.run(as_of=as_of, top_n=top_n)
                    results.append(out)
                    
                    progress.update(task, advance=30, description=f"[cyan]åœ°åŸŸ {region} ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
                    out_path = Path(cfg.output_dir) / f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json"
                    write_json(out_path, out)
                    
                    # æˆé•·å€™è£œã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    growth_out_path = Path(cfg.output_dir) / f"growth_{region}_{as_of.strftime('%Y%m%d')}.json"
                    write_json(
                        growth_out_path,
                        {
                            "region": region,
                            "as_of": as_of.strftime("%Y-%m-%d"),
                            "universe": out.get("universe", "REAL"),
                            "candidates": out.get("growth_candidates", []),
                        },
                    )
                    
                    progress.update(task, advance=20, description=f"[green]åœ°åŸŸ {region} å®Œäº†")
                    console.print(f"âœ… [green]candidates saved:[/green] {out_path}")
                    console.print(f"âœ… [green]growth saved:[/green] {growth_out_path}")
    else:
        print(f"[bold]Regions:[/bold] {region_list}  Date: {as_of}")
        
        results: List[dict] = []
        for region in region_list:
            agent = RegionAgent(name=region, universe="REAL", tools={
                "marketdata": MarketDataClient(max_workers=workers),
                "fundamentals": FundamentalsClient(max_workers=workers),
                "news": NewsClient(max_workers=min(workers, 3))
            })
            out = agent.run(as_of=as_of, top_n=top_n)
            results.append(out)
            out_path = Path(cfg.output_dir) / f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json"
            write_json(out_path, out)
            print(f"âœ… candidates saved: {out_path}")
            # æˆé•·å€™è£œã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            growth_out_path = Path(cfg.output_dir) / f"growth_{region}_{as_of.strftime('%Y%m%d')}.json"
            write_json(
                growth_out_path,
                {
                    "region": region,
                    "as_of": as_of.strftime("%Y-%m-%d"),
                    "universe": out.get("universe", "REAL"),
                    "candidates": out.get("growth_candidates", []),
                },
            )
            print(f"âœ… growth saved: {growth_out_path}")

    console.print(Panel("[bold green]å€™è£œé¸å®šå®Œäº†[/bold green]", title="çµæœ"))
    print("done.")


@app.command()
def report(
    input: str = typer.Option(..., help="æœ€çµ‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªJSONã®ãƒ‘ã‚¹"),
    output: str = typer.Option("./artifacts", help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãªé€²æ—è¡¨ç¤º"),
):
    """æœ€çµ‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‹ã‚‰Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã€‚"""
    cfg = load_config(output)
    ensure_output_dir(cfg.output_dir)

    if verbose:
        console.print(Panel("[bold blue]ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹[/bold blue]", title="å®Ÿè¡Œæƒ…å ±"))
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            task = progress.add_task("[cyan]ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªèª­ã¿è¾¼ã¿ä¸­...", total=100)
            progress.update(task, advance=30)
            
            with open(input, "r", encoding="utf-8") as f:
                portfolio = json.load(f)
            
            progress.update(task, advance=30, description="[cyan]ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            md = build_report(candidates_all=[], portfolio=portfolio, kpi={})
            
            progress.update(task, advance=20, description="[cyan]ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            as_of = portfolio.get("as_of", datetime.today().strftime("%Y-%m-%d"))
            out_md = Path(cfg.output_dir) / f"report_{as_of.replace('-', '')}.md"
            write_text(out_md, md)
            
            progress.update(task, advance=20, description="[green]å®Œäº†")
    else:
        with open(input, "r", encoding="utf-8") as f:
            portfolio = json.load(f)

        md = build_report(candidates_all=[], portfolio=portfolio, kpi={})
        as_of = portfolio.get("as_of", datetime.today().strftime("%Y-%m-%d"))
        out_md = Path(cfg.output_dir) / f"report_{as_of.replace('-', '')}.md"
        write_text(out_md, md)
        print(f"âœ… report saved: {out_md}")


@app.command()
def run(
    regions: str = typer.Option("JP,US", help="å¯¾è±¡åœ°åŸŸ (CSV)"),
    run_date: str = typer.Option(datetime.today().strftime("%Y-%m-%d"), "--date"),
    output: str = typer.Option("./artifacts", help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"),
    top_n: int = typer.Option(50, help="å„åœ°åŸŸã®ä¸Šä½å€™è£œæ•°"),
    risk_aversion: float = typer.Option(0.0, help="ãƒªã‚¹ã‚¯è¨±å®¹åº¦ï¼ˆå¤§ãã„ã»ã©ãƒªã‚¿ãƒ¼ãƒ³é‡è¦–ï¼‰ã€‚0ã§ãƒœãƒ©æœ€å°ã€‚"),
    target_vol: Optional[float] = typer.Option(None, help="å¹´ç‡ãƒœãƒ©ä¸Šé™ï¼ˆä¾‹: 0.18ï¼‰ã€‚æœªæŒ‡å®šã§åˆ¶ç´„ãªã—ã€‚"),
    target: str = typer.Option("min_vol", help="ç›®çš„é–¢æ•°: min_vol / max_returnï¼ˆrisk_aversion>0 ãªã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰ã€‚"),
    macro_csv: Optional[str] = typer.Option(None, help="ãƒã‚¯ãƒ­åˆæœŸé‡ã¿CSVã®ãƒ‘ã‚¹ï¼ˆregion,weightï¼‰ã€‚æœªæŒ‡å®šã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡ã¿ã€‚"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãªé€²æ—è¡¨ç¤º"),
    parallel: bool = typer.Option(True, "--parallel/--sequential", help="ä¸¦åˆ—å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã¾ãŸã¯é€æ¬¡å®Ÿè¡Œ"),
    workers: int = typer.Option(4, "--workers", "-w", help="ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4ï¼‰"),
):
    """é€±æ¬¡ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Ÿè¡Œã€‚å€™è£œâ†’æœ€é©åŒ–â†’ãƒ¬ãƒå‡ºåŠ›ã€‚"""
    as_of = _parse_date(run_date)
    cfg = load_config(output)
    ensure_output_dir(cfg.output_dir)

    region_list = [r.strip().upper() for r in regions.split(",") if r.strip()]
    
    if verbose:
        console.print(Panel(
            f"[bold blue]é€±æ¬¡ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Ÿè¡Œé–‹å§‹[/bold blue]\n"
            f"åœ°åŸŸ: {', '.join(region_list)}  æ—¥ä»˜: {as_of}\n"
            f"ãƒªã‚¹ã‚¯è¨±å®¹åº¦: {risk_aversion}  ç›®çš„: {target}\n"
            f"å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {'ä¸¦åˆ—' if parallel else 'é€æ¬¡'}",
            title="å®Ÿè¡Œæƒ…å ±"
        ))
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=console
        ) as progress:
            # ãƒã‚¯ãƒ­ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
            task_macro = progress.add_task("[cyan]ãƒã‚¯ãƒ­åˆ†æä¸­...", total=100)
            progress.update(task_macro, advance=50)
            macro_agent = MacroAgent(csv_path=macro_csv)
            macro_weights = macro_agent.propose(region_list)
            progress.update(task_macro, advance=50, description="[green]ãƒã‚¯ãƒ­åˆ†æå®Œäº†")
            
            # åœ°åŸŸåˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆä¸¦åˆ—ã¾ãŸã¯é€æ¬¡ï¼‰
            candidates_all: List[dict] = []
            region_prices: dict[str, "pd.DataFrame"] = {}
            
            if parallel and len(region_list) > 1:
                # ä¸¦åˆ—å®Ÿè¡Œ
                tasks = {}
                with ThreadPoolExecutor(max_workers=min(len(region_list), workers)) as executor:
                    # ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
                    for region in region_list:
                        task_id = progress.add_task(f"[cyan]åœ°åŸŸ {region} å‡¦ç†ä¸­...", total=100)
                        future = executor.submit(_process_region_parallel, region, as_of, top_n, Path(cfg.output_dir), progress, task_id)
                        tasks[future] = (region, task_id)
                    
                    # å®Œäº†ã‚’å¾…æ©Ÿ
                    for future in as_completed(tasks):
                        region, task_id = tasks[future]
                        try:
                            region_name, out, prices = future.result()
                            candidates_all.append(out)
                            region_prices[region_name] = prices
                        except Exception as e:
                            console.print(f"âŒ [red]åœ°åŸŸ {region} ã§ã‚¨ãƒ©ãƒ¼:[/red] {str(e)}")
            else:
                # é€æ¬¡å®Ÿè¡Œï¼ˆæ—¢å­˜ã®å®Ÿè£…ï¼‰
                for i, region in enumerate(region_list):
                    task_region = progress.add_task(f"[cyan]åœ°åŸŸ {region} å‡¦ç†ä¸­...", total=100)
                    
                    progress.update(task_region, advance=20, description=f"[cyan]åœ°åŸŸ {region} ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")
                    agent = RegionAgent(name=region, universe="REAL", tools={
                        "marketdata": MarketDataClient(max_workers=workers),
                        "fundamentals": FundamentalsClient(max_workers=workers),
                        "news": NewsClient(max_workers=min(workers, 3))
                    })
                    
                    progress.update(task_region, advance=30, description=f"[cyan]åœ°åŸŸ {region} å€™è£œé¸å®šä¸­...")
                    out = agent.run(as_of=as_of, top_n=top_n)
                    candidates_all.append(out)
                    
                    progress.update(task_region, advance=20, description=f"[cyan]åœ°åŸŸ {region} ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
                    out_path = Path(cfg.output_dir) / f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json"
                    write_json(out_path, out)
                    
                    # æˆé•·å€™è£œã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    growth_out_path = Path(cfg.output_dir) / f"growth_{region}_{as_of.strftime('%Y%m%d')}.json"
                    write_json(
                        growth_out_path,
                        {
                            "region": region,
                            "as_of": as_of.strftime("%Y-%m-%d"),
                            "universe": out.get("universe", "REAL"),
                            "candidates": out.get("growth_candidates", []),
                        },
                    )
                    
                    progress.update(task_region, advance=20, description=f"[cyan]åœ°åŸŸ {region} ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
                    mkt = MarketDataClient(max_workers=workers)
                    uni_tickers = [c["ticker"] for c in out.get("candidates", [])]
                    if uni_tickers:
                        prices, _ = mkt.get_prices(uni_tickers, lookback_days=260)
                        region_prices[region] = prices
                    
                    progress.update(task_region, advance=10, description=f"[green]åœ°åŸŸ {region} å®Œäº†")
            
            # ä¾¡æ ¼çµ±åˆ
            task_prices = progress.add_task("[cyan]ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...", total=100)
            progress.update(task_prices, advance=50)
            import pandas as pd  # local import to avoid global dependency at import time
            all_prices = None
            for p in region_prices.values():
                if p is None or p.empty:
                    continue
                all_prices = p if all_prices is None else all_prices.join(p, how="outer")
            progress.update(task_prices, advance=50, description="[green]ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
            
            # æœ€é©åŒ–
            task_optimize = progress.add_task("[cyan]ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ä¸­...", total=100)
            progress.update(task_optimize, advance=50)
            portfolio = optimize_portfolio(
                candidates_by_region=candidates_all,
                constraints={
                    "region_limits": cfg.region_limits,
                    "position_limit": cfg.position_limit,
                    "cash_min": cfg.cash_min,
                    "cash_max": cfg.cash_max,
                    "as_of": as_of.strftime("%Y-%m-%d"),
                    "risk_aversion": risk_aversion,
                    "target_vol": target_vol,
                    "target": target,
                },
                prices_df=all_prices,
            )
            progress.update(task_optimize, advance=50, description="[green]æœ€é©åŒ–å®Œäº†")
            
            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿å­˜
            task_save = progress.add_task("[cyan]ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿å­˜ä¸­...", total=100)
            progress.update(task_save, advance=50)
            port_path = Path(cfg.output_dir) / f"portfolio_{as_of.strftime('%Y%m%d')}.json"
            write_json(port_path, portfolio)
            progress.update(task_save, advance=50, description="[green]ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿å­˜å®Œäº†")
            
            # ãƒªã‚¹ã‚¯è¨ˆç®—
            task_risk = progress.add_task("[cyan]ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—ä¸­...", total=100)
            progress.update(task_risk, advance=50)
            risk_agent = RiskAgent()
            risk = risk_agent.run(price_panels=region_prices, combined_prices=all_prices)
            risk_path = Path(cfg.output_dir) / f"risk_{as_of.strftime('%Y%m%d')}.json"
            write_json(risk_path, risk)
            progress.update(task_risk, advance=50, description="[green]ãƒªã‚¹ã‚¯è¨ˆç®—å®Œäº†")
            
            # å›³ã®ä¿å­˜
            task_images = progress.add_task("[cyan]å¯è¦–åŒ–ç”»åƒç”Ÿæˆä¸­...", total=100)
            progress.update(task_images, advance=50)
            images = {}
            try:
                from .agents.chair import save_correlation_heatmap, save_allocation_pie
                corr_dict = (risk or {}).get("metrics", {}).get("correlation")
                corr_png = Path(cfg.output_dir) / f"corr_{as_of.strftime('%Y%m%d')}.png"
                save_correlation_heatmap(corr_dict, str(corr_png))
                images["correlation_heatmap"] = str(corr_png)
                pie_png = Path(cfg.output_dir) / f"alloc_{as_of.strftime('%Y%m%d')}.png"
                save_allocation_pie(portfolio, str(pie_png))
                images["allocation_pie"] = str(pie_png)
            except Exception:
                images = {}
            progress.update(task_images, advance=50, description="[green]å¯è¦–åŒ–å®Œäº†")
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            task_report = progress.add_task("[cyan]ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...", total=100)
            progress.update(task_report, advance=50)
            md = build_report(candidates_all=candidates_all, portfolio=portfolio, kpi=risk, macro=macro_weights, images=images)
            out_md = Path(cfg.output_dir) / f"report_{as_of.strftime('%Y%m%d')}.md"
            write_text(out_md, md)
            progress.update(task_report, advance=50, description="[green]ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
        
        # çµæœã‚µãƒãƒªãƒ¼
        table = Table(title="ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«")
        table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="cyan")
        table.add_column("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", style="green")
        
        for region in region_list:
            table.add_row(f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json", "âœ… å®Œäº†")
            table.add_row(f"growth_{region}_{as_of.strftime('%Y%m%d')}.json", "âœ… å®Œäº†")
        
        table.add_row(f"portfolio_{as_of.strftime('%Y%m%d')}.json", "âœ… å®Œäº†")
        table.add_row(f"risk_{as_of.strftime('%Y%m%d')}.json", "âœ… å®Œäº†")
        table.add_row(f"report_{as_of.strftime('%Y%m%d')}.md", "âœ… å®Œäº†")
        if images:
            table.add_row(f"corr_{as_of.strftime('%Y%m%d')}.png", "âœ… å®Œäº†")
            table.add_row(f"alloc_{as_of.strftime('%Y%m%d')}.png", "âœ… å®Œäº†")
        
        console.print(table)
        console.print(Panel("[bold green]é€±æ¬¡å®Ÿè¡Œå®Œäº†[/bold green]", title="çµæœ"))
        
    else:
        print(f"[bold]Run weekly[/bold] regions={region_list} date={as_of}")

        # macro: åœ°åŸŸåˆæœŸé‡ã¿ï¼ˆå‚è€ƒï¼‰
        macro_agent = MacroAgent(csv_path=macro_csv)
        macro_weights = macro_agent.propose(region_list)

        candidates_all: List[dict] = []
        region_prices: dict[str, "pd.DataFrame"] = {}
        for region in region_list:
            agent = RegionAgent(name=region, universe="REAL", tools={"marketdata": MarketDataClient()})
            out = agent.run(as_of=as_of, top_n=top_n)
            candidates_all.append(out)
            out_path = Path(cfg.output_dir) / f"candidates_{region}_{as_of.strftime('%Y%m%d')}.json"
            write_json(out_path, out)
            # ä¾¡æ ¼ã‚’å†å–å¾—ï¼ˆæœ€é©åŒ–/ãƒªã‚¹ã‚¯ç”¨ï¼‰ï¼šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå†…éƒ¨ã®MarketDataã¨åŒç­‰å–å¾—
            # æˆé•·å€™è£œã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            growth_out_path = Path(cfg.output_dir) / f"growth_{region}_{as_of.strftime('%Y%m%d')}.json"
            write_json(
                growth_out_path,
                {
                    "region": region,
                    "as_of": as_of.strftime("%Y-%m-%d"),
                    "universe": out.get("universe", "REAL"),
                    "candidates": out.get("growth_candidates", []),
                },
            )
            print(f"âœ… growth saved: {growth_out_path}")
            mkt = MarketDataClient()
            uni_tickers = [c["ticker"] for c in out.get("candidates", [])]
            if uni_tickers:
                prices, _ = mkt.get_prices(uni_tickers, lookback_days=260)
                region_prices[region] = prices

        # ä¾¡æ ¼ã‚’çµ±åˆï¼ˆåˆ—=ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼‰
        import pandas as pd  # local import to avoid global dependency at import time
        all_prices = None
        for p in region_prices.values():
            if p is None or p.empty:
                continue
            all_prices = p if all_prices is None else all_prices.join(p, how="outer")

        portfolio = optimize_portfolio(
            candidates_by_region=candidates_all,
            constraints={
                "region_limits": cfg.region_limits,
                "position_limit": cfg.position_limit,
                "cash_min": cfg.cash_min,
                "cash_max": cfg.cash_max,
                "as_of": as_of.strftime("%Y-%m-%d"),
                "risk_aversion": risk_aversion,
                "target_vol": target_vol,
                "target": target,
            },
            prices_df=all_prices,
        )

        port_path = Path(cfg.output_dir) / f"portfolio_{as_of.strftime('%Y%m%d')}.json"
        write_json(port_path, portfolio)
        print(f"âœ… portfolio saved: {port_path}")

        # ãƒªã‚¹ã‚¯æŒ‡æ¨™ã‚’è¨ˆç®—ãƒ»ä¿å­˜
        risk_agent = RiskAgent()
        risk = risk_agent.run(price_panels=region_prices, combined_prices=all_prices)
        risk_path = Path(cfg.output_dir) / f"risk_{as_of.strftime('%Y%m%d')}.json"
        write_json(risk_path, risk)

        # å›³ã®ä¿å­˜ï¼ˆç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã€é…åˆ†å††ã‚°ãƒ©ãƒ•ï¼‰
        images = {}
        try:
            from .agents.chair import save_correlation_heatmap, save_allocation_pie
            corr_dict = (risk or {}).get("metrics", {}).get("correlation")
            corr_png = Path(cfg.output_dir) / f"corr_{as_of.strftime('%Y%m%d')}.png"
            save_correlation_heatmap(corr_dict, str(corr_png))
            images["correlation_heatmap"] = str(corr_png)
            pie_png = Path(cfg.output_dir) / f"alloc_{as_of.strftime('%Y%m%d')}.png"
            save_allocation_pie(portfolio, str(pie_png))
            images["allocation_pie"] = str(pie_png)
        except Exception:
            images = {}

        md = build_report(candidates_all=candidates_all, portfolio=portfolio, kpi=risk, macro=macro_weights, images=images)
        out_md = Path(cfg.output_dir) / f"report_{as_of.strftime('%Y%m%d')}.md"
        write_text(out_md, md)
        print(f"âœ… report saved: {out_md}")


@app.command()
def buy_signal(
    regions: str = typer.Option("JP,US", help="å¯¾è±¡åœ°åŸŸ (CSV)"),
    run_date: str = typer.Option(datetime.today().strftime("%Y-%m-%d"), "--date"),
    output: str = typer.Option("./artifacts", help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"),
    pe_threshold: float = typer.Option(15.0, help="P/Eæ¯”ç‡ã®é–¾å€¤"),
    pb_threshold: float = typer.Option(1.5, help="P/Bæ¯”ç‡ã®é–¾å€¤"),
    revenue_growth_threshold: float = typer.Option(0.05, help="å£²ä¸Šæˆé•·ç‡ã®é–¾å€¤"),
    eps_growth_threshold: float = typer.Option(0.10, help="EPSæˆé•·ç‡ã®é–¾å€¤"),
    peg_ratio_threshold: float = typer.Option(1.0, help="PEGæ¯”ç‡ã®é–¾å€¤"),
    min_signals: int = typer.Option(3, help="BUYåˆ¤å®šã«å¿…è¦ãªæ¡ä»¶æ•°"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãªé€²æ—è¡¨ç¤º"),
):
    """è²·ã„ã‚·ã‚°ãƒŠãƒ«ã‚’è©•ä¾¡ã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›"""
    cfg = load_config(output)
    ensure_output_dir(cfg.output_dir)
    
    as_of = _parse_date(run_date)
    region_list = [r.strip() for r in regions.split(",")]
    
    if verbose:
        console.print(f"[bold]Buy Signal Analysis[/bold] regions={region_list} date={as_of}")
    
    all_tickers = []
    for region in region_list:
        try:
            uni = load_universe(region)
            all_tickers.extend(uni["ticker"].tolist())
        except Exception as e:
            console.print(f"âŒ [red]åœ°åŸŸ {region} ã®ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:[/red] {str(e)}")
    
    if not all_tickers:
        console.print("[red]å‡¦ç†å¯¾è±¡ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/red]")
        return
    
    if verbose:
        console.print(f"ğŸ“Š [cyan]è©•ä¾¡å¯¾è±¡: {len(all_tickers)} ãƒ†ã‚£ãƒƒã‚«ãƒ¼[/cyan]")
    
    # buy_signalè©•ä¾¡å®Ÿè¡Œ
    result_df = evaluate_buy_signals(
        tickers=all_tickers,
        pe_threshold=pe_threshold,
        pb_threshold=pb_threshold,
        revenue_growth_threshold=revenue_growth_threshold,
        eps_growth_threshold=eps_growth_threshold,
        peg_ratio_threshold=peg_ratio_threshold,
        min_signals=min_signals,
    )
    
    # çµæœã‚’CSVã«ä¿å­˜
    output_path = Path(cfg.output_dir) / f"buy_signals_{as_of.strftime('%Y%m%d')}.csv"
    result_df.to_csv(output_path, index=False)
    
    # BUYåˆ¤å®šã•ã‚ŒãŸéŠ˜æŸ„ã‚’è¡¨ç¤º
    buy_candidates = result_df[result_df["decision"] == "BUY"]
    
    if verbose:
        console.print(f"âœ… [green]buy_signals saved:[/green] {output_path}")
        console.print(f"ğŸ“ˆ [green]BUYåˆ¤å®š: {len(buy_candidates)} éŠ˜æŸ„[/green]")
        
        if not buy_candidates.empty:
            table = Table(title="BUYåˆ¤å®šéŠ˜æŸ„")
            table.add_column("ãƒ†ã‚£ãƒƒã‚«ãƒ¼", style="cyan")
            table.add_column("P/E", style="yellow")
            table.add_column("P/B", style="yellow")
            table.add_column("å£²ä¸Šæˆé•·", style="green")
            table.add_column("EPSæˆé•·", style="green")
            table.add_column("PEG", style="yellow")
            table.add_column("ã‚¹ã‚³ã‚¢", style="bold")
            
            for _, row in buy_candidates.head(20).iterrows():
                table.add_row(
                    row["ticker"],
                    f"{row['pe']:.2f}" if pd.notna(row['pe']) else "N/A",
                    f"{row['pb']:.2f}" if pd.notna(row['pb']) else "N/A",
                    f"{row['revenue_growth']:.1%}" if pd.notna(row['revenue_growth']) else "N/A",
                    f"{row['eps_growth']:.1%}" if pd.notna(row['eps_growth']) else "N/A",
                    f"{row['peg_ratio']:.2f}" if pd.notna(row['peg_ratio']) else "N/A",
                    str(row['score'])
                )
            console.print(table)
    
    console.print(Panel(f"[bold green]è²·ã„ã‚·ã‚°ãƒŠãƒ«åˆ†æå®Œäº†[/bold green]\nBUYåˆ¤å®š: {len(buy_candidates)} éŠ˜æŸ„", title="çµæœ"))


if __name__ == "__main__":
    app()


